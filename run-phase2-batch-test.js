import "dotenv/config";
import { SupabaseClient } from './src/database/supabase-client.js';
import { Logger } from './src/utils/logger.js';
import OpenAI from 'openai';
import fs from 'fs-extra';
import path from 'path';

const logger = new Logger();

class URLBasedAIAnalyzerBatch {
  constructor() {
    this.logger = new Logger();
    this.openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    this.totalCost = 0;
    this.totalTokens = 0;
    this.processedCount = 0;
    this.batchDir = 'temp/batch_jobs';
  }

  async process(images) {
    this.logger.info(`ğŸš€ Starting BATCH AI analysis - Processing ${images.length} images with 50% cost savings`);
    
    // Ensure batch directory exists
    await fs.ensureDir(this.batchDir);
    
    // Create batch tasks
    const batchTasks = await this.createBatchTasks(images);
    
    // Upload batch file and create job
    const batchJob = await this.createBatchJob(batchTasks);
    
    // Wait for completion and get results
    const results = await this.waitAndGetResults(batchJob);
    
    // Process and return results
    return this.processResults(results, images);
  }

  async createBatchTasks(images) {
    this.logger.info(`ğŸ“¦ Creating batch tasks for ${images.length} images`);
    
    const tasks = [];
    
    for (let i = 0; i < images.length; i++) {
      const item = images[i];
      
      // Validate required fields
      if (!item.postId || !item.imagePath) {
        this.logger.error(`âŒ Skipping invalid image item: missing postId or imagePath`);
        continue;
      }

      try {
        // Download image from URL and convert to base64
        const response = await fetch(item.imagePath);
        if (!response.ok) {
          throw new Error(`Failed to fetch image: ${response.status} ${response.statusText}`);
        }
        const imageBuffer = await response.arrayBuffer();
        const base64Image = Buffer.from(imageBuffer).toString('base64');

        const task = {
          custom_id: `task-${i}-${item.postId}`,
          method: "POST",
          url: "/v1/chat/completions",
          body: {
            model: 'gpt-4o-mini',
            messages: [
              {
                role: 'user',
                content: [
                  { 
                    type: 'text', 
                    text: `Analyze this fashion image for rich context. Return JSON: {\n  "a": "aesthetic (e.g., streetwear, y2k, preppy)",\n  "c": ["primary colors"],\n  "s": "season (spring, summer, fall, winter)",\n  "o": "occasion (casual, formal, party, workout)",\n  "ad": ["additional themes like 'back to school', 'date night', 'vacation'"]\n}` 
                  },
                  { 
                    type: 'image_url', 
                    image_url: { url: `data:image/jpeg;base64,${base64Image}` } 
                  }
                ]
              }
            ],
            max_tokens: 120,
            temperature: 0
          }
        };
        
        tasks.push(task);
        
        if ((i + 1) % 50 === 0) {
          this.logger.info(`ğŸ“ Created ${i + 1}/${images.length} batch tasks`);
        }
        
      } catch (err) {
        this.logger.error(`Failed to process image ${item.imagePath}: ${err.message}`);
        continue;
      }
    }
    
    this.logger.info(`âœ… Created ${tasks.length} batch tasks`);
    return tasks;
  }

  async createBatchJob(tasks) {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const batchFileName = path.join(this.batchDir, `fashion_batch_${timestamp}.jsonl`);
    
    // Write tasks to JSONL file
    this.logger.info(`ğŸ’¾ Writing batch file: ${batchFileName}`);
    const fileContent = tasks.map(task => JSON.stringify(task)).join('\n');
    await fs.writeFile(batchFileName, fileContent);
    
    // Upload file to OpenAI
    this.logger.info(`ğŸ“¤ Uploading batch file to OpenAI...`);
    const batchFile = await this.openai.files.create({
      file: fs.createReadStream(batchFileName),
      purpose: "batch"
    });
    
    // Create batch job
    this.logger.info(`ğŸš€ Creating batch job...`);
    const batchJob = await this.openai.batches.create({
      input_file_id: batchFile.id,
      endpoint: "/v1/chat/completions",
      completion_window: "24h"
    });
    
    this.logger.info(`âœ… Batch job created: ${batchJob.id}`);
    this.logger.info(`ğŸ“Š Status: ${batchJob.status}`);
    this.logger.info(`ğŸ’° Expected 50% cost savings vs individual API calls`);
    
    return batchJob;
  }

  async waitAndGetResults(batchJob) {
    this.logger.info(`â³ Waiting for batch job completion (max 24h)...`);
    
    let job = batchJob;
    const maxWaitTime = 24 * 60 * 60 * 1000; // 24 hours
    const startTime = Date.now();
    const checkInterval = 30000; // Check every 30 seconds
    
    while (job.status === 'validating' || job.status === 'in_progress' || job.status === 'finalizing') {
      if (Date.now() - startTime > maxWaitTime) {
        throw new Error('Batch job timed out after 24 hours');
      }
      
      await new Promise(resolve => setTimeout(resolve, checkInterval));
      
      job = await this.openai.batches.retrieve(job.id);
      this.logger.info(`ğŸ“Š Batch status: ${job.status} | Completed: ${job.request_counts?.completed || 0}/${job.request_counts?.total || 0}`);
    }
    
    if (job.status === 'completed') {
      this.logger.info(`âœ… Batch job completed successfully!`);
      
      // Download results
      const resultFileContent = await this.openai.files.content(job.output_file_id);
      const resultsText = Buffer.from(await resultFileContent.arrayBuffer()).toString();
      
      // Save results locally
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const resultsFileName = path.join(this.batchDir, `results_${timestamp}.jsonl`);
      await fs.writeFile(resultsFileName, resultsText);
      
      // Parse results
      const results = resultsText.trim().split('\n').map(line => JSON.parse(line));
      
      this.logger.info(`ğŸ“Š Processing ${results.length} batch results`);
      return results;
      
    } else if (job.status === 'failed') {
      throw new Error(`Batch job failed: ${job.errors?.[0]?.message || 'Unknown error'}`);
    } else {
      throw new Error(`Unexpected batch job status: ${job.status}`);
    }
  }

  processResults(batchResults, originalImages) {
    this.logger.info(`ğŸ”„ Processing batch results...`);
    
    const processedResults = [];
    
    for (const batchResult of batchResults) {
      try {
        // Find corresponding original image
        const originalImage = originalImages.find(img => 
          batchResult.custom_id === `task-${originalImages.indexOf(img)}-${img.postId}`
        );
        
        if (!originalImage) {
          this.logger.warn(`Could not find original image for batch result: ${batchResult.custom_id}`);
          continue;
        }
        
        // Parse the response
        const responseBody = batchResult.response?.body?.choices?.[0]?.message?.content;
        if (!responseBody) {
          this.logger.warn(`No response body for batch result: ${batchResult.custom_id}`);
          continue;
        }
        
        // Handle JSON wrapped in markdown code blocks
        let jsonText = responseBody.trim();
        if (jsonText.includes('```json')) {
          jsonText = jsonText.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
        } else if (jsonText.includes('```')) {
          jsonText = jsonText.replace(/```\n?/g, '').trim();
        }
        
        const analysis = JSON.parse(jsonText);
        
        // Track costs
        const promptTokens = batchResult.response?.body?.usage?.prompt_tokens || 0;
        const completionTokens = batchResult.response?.body?.usage?.completion_tokens || 0;
        const cost = (promptTokens * 0.000150 / 1000) + (completionTokens * 0.000600 / 1000);
        
        this.totalCost += cost;
        this.totalTokens += (promptTokens + completionTokens);
        this.processedCount++;
        
        processedResults.push({
          image_id: originalImage.id,
          post_id: originalImage.postId,
          username: originalImage.username,
          image_path: originalImage.imagePath,
          analysis: analysis,
          engagement: originalImage.engagement
        });
        
      } catch (err) {
        this.logger.error(`Failed to process batch result: ${err.message}`);
        continue;
      }
    }
    
    this.logger.info(`âœ… Processed ${processedResults.length} results from batch`);
    return processedResults;
  }

  getCostSummary() {
    return {
      totalCost: this.totalCost,
      totalTokens: this.totalTokens,
      processedCount: this.processedCount,
      averageCostPerImage: this.processedCount > 0 ? this.totalCost / this.processedCount : 0
    };
  }
}

async function runPhase2BatchTest() {
  try {
    logger.info('ğŸš€ Starting Phase 2.1 Batch Test: Rich Context Analysis (100 images)');
    logger.info('ğŸš€ This will test batching with 50% cost savings on a larger dataset');
    
    // Initialize database
    const db = new SupabaseClient();
    
    // Get 100 images from database with engagement data from posts table
    logger.info('ğŸš€ Fetching 100 images from database with engagement data...');
    const { data: images, error } = await db.client
      .from('images')
      .select(`
        id,
        image_path,
        post_id,
        username,
        posts!inner(
          like_count,
          comment_count,
          view_count,
          save_count,
          engagement_rate
        )
      `)
      .limit(150); // Get more images so we can sort by engagement
    
    if (error) {
      throw new Error(`Database error: ${error.message}`);
    }
    
    if (!images || images.length === 0) {
      throw new Error('No images found in database');
    }
    
    // Sort by engagement rate and take top 100
    const sortedImages = images
      .filter(img => img.posts && img.posts.like_count)
      .sort((a, b) => (b.posts.like_count || 0) - (a.posts.like_count || 0))
      .slice(0, 100);
    
    logger.info(`âœ… Found ${sortedImages.length} images to analyze (sorted by engagement)`);
    
    // Convert to format expected by batch analyzer
    const batchImages = sortedImages.map(img => ({
      id: img.id,
      postId: img.post_id,
      username: img.username,
      imagePath: img.image_path,
      engagement: {
        likes: img.posts.like_count,
        comments: img.posts.comment_count,
        views: img.posts.view_count,
        saves: img.posts.save_count,
        engagement_rate: img.posts.engagement_rate
      }
    }));
    
    // Run batch analysis
    logger.info('ğŸš€ Starting batch analysis...');
    const batchAnalyzer = new URLBasedAIAnalyzerBatch();
    const results = await batchAnalyzer.process(batchImages);
    
    // Get cost summary
    const costSummary = batchAnalyzer.getCostSummary();
    
    // Display results
    logger.info('ğŸ‰ Phase 2.1 Batch Test Complete!');
    logger.info(`ğŸ“Š Results Summary:`);
    logger.info(`   âœ… Images processed: ${costSummary.processedCount}/${sortedImages.length}`);
    logger.info(`   ğŸ’° Total cost: $${costSummary.totalCost.toFixed(4)}`);
    logger.info(`   ğŸ§  Total tokens: ${costSummary.totalTokens}`);
    logger.info(`   ğŸ’¸ Average cost per image: $${costSummary.averageCostPerImage.toFixed(6)}`);
    logger.info(`   ğŸ’° Estimated cost for 8k images: $${(costSummary.totalCost * 80).toFixed(2)}`);
    
    // Show sample results
    logger.info('\nğŸ“‹ Sample Analysis Results:');
    results.slice(0, 3).forEach((result, i) => {
      logger.info(`   ${i + 1}. Post ${result.post_id} (@${result.username}):`);
      logger.info(`      Aesthetic: ${result.analysis.a}`);
      logger.info(`      Colors: ${result.analysis.c.join(', ')}`);
      logger.info(`      Season: ${result.analysis.s}`);
      logger.info(`      Occasion: ${result.analysis.o}`);
      logger.info(`      Themes: ${result.analysis.ad.join(', ')}`);
      logger.info(`      Engagement: ${result.engagement.likes} likes`);
    });
    
    // Store results in database
    logger.info('\nğŸš€ Storing results in database...');
    for (const result of results) {
      try {
        await db.client
          .from('images')
          .update({
            aesthetic: result.analysis.a,
            colors: result.analysis.c,
            season: result.analysis.s,
            occasion: result.analysis.o,
            additional_themes: result.analysis.ad,
            updated_at: new Date().toISOString()
          })
          .eq('id', result.image_id);
      } catch (err) {
        logger.error(`Failed to update image ${result.image_id}: ${err.message}`);
      }
    }
    
    logger.info('âœ… Results stored in database');
    logger.info('\nğŸ¯ Phase 2.1 Batch Test Summary:');
    logger.info(`   âœ… Batch processing working correctly`);
    logger.info(`   âœ… URL image handling working correctly`);
    logger.info(`   âœ… Database storage working correctly`);
    logger.info(`   ğŸ’° Cost for 100 images: $${costSummary.totalCost.toFixed(4)}`);
    logger.info(`   ğŸ’° Estimated cost for 8k images: $${(costSummary.totalCost * 80).toFixed(2)}`);
    logger.info(`   ğŸ’° 50% cost savings confirmed!`);
    logger.info('\nğŸš€ Ready to run full Phase 2.1 on all 8k images!');
    
  } catch (error) {
    logger.error(`âŒ Phase 2.1 batch test failed: ${error.message}`);
    console.error(error.stack);
    process.exit(1);
  }
}

// Run the test
runPhase2BatchTest();
